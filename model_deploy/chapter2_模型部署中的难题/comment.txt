第二章  模型部署中的难题
第一章的SRCNN模型只包含几个简单的 算子，而这些 卷积、插值算子已经在各中间表示和推理引擎上得到 完美支持，但如果模型的操作稍微复杂一点，就要为兼容模型而付出大量的功夫。

1.模型的动态化（模型本身）
出于性能的考虑，各推理框架都默认模型的输入形状、输出形状、结构是静态的，但为了让模型的泛用性更强，部署时需要在尽可能不影响原有逻辑的前提下，让模型的输入输出或是结构动态化。

2.新算子的实现
深度学习技术日新月异，提出torch新算子的速度往往快于 ONNX 维护者支持的速度。为了部署最新的模型，部署工程师往往需要自己在 ONNX 和推理引擎中支持新算子。

3.中间表示(ONNX) 与 推理引擎（TensorRT、ncnn、CANN）的兼容问题
各推理引擎的实现不同，对ONNX难以形成统一的支持。为了确保模型在不同的推理引擎中有同样的运行效果，部署工程师往往得为某个推理引擎定制模型代码。

